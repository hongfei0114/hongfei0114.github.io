---
layout:     post
title:      K8S杂货铺
subtitle:   K8S杂货铺
date:       2020-03-10
author:     hongfei
header-img: img/post-bg-debug.png
catalog: true
tags:
    - Kubernetes
    - K8S
    - helm
    
---


# k8S
## k8s pod的理解

PodIP是动态变化的 

## 应用封装容器
代码与配置的分离

1. 环境变量
    1. 传配置
2. 多套配置文件，重新build
    1. 管理复杂、变更困难
3. 配置中心 根据客户端的ip判断你是什么环境，给你推送相应的配置
    1. 最好的方式

以上1和2，都无法保证环境的一致性。重新build了

把容器放在Pod中，如何做资源限制，如何做健康检查
如何发现Pod中的容器挂了？


service 严格意义上来说，并不是负载均衡。 
    简单点说，四层。依靠kube-proxy+LVS实现
    
hostport 类似 docker run -p 的作用


Ingress Controller
Ingress 代理的并不是service的IP，而是直接代理到了Pod的IP



K8S集群 以后的重点

*  网工 
*  存储

```bash
kubectl get pod --all-namespaces
```

外网流量入口机器，给ingress机器打标签。

ingress 配置`hostnamework true`  用host网络模式，把宿主机的IP当做流量入口。


生产 拉镜像
自动化创建secret secret分权限



##

Pod Hooks

资源限制：


### PV PVC
```bash
mkdir /export/k8s
chmod 755 /export/k8s
yum –y install nfs-utils rpcbind
vi /etc/exports
/export/k8s *(rw,sync,no_root_squash)
systemctl start rpcbind nfs
systemctl enable rpcbind nfs
systemctl status rpcbind nfs

# 客户端安装：
yum –y install rpcbind nfs
```



### HPA 自动伸缩
(只能考虑到cpu mem)


pod的概念

label的理解 用处

手动删除Pod中的docker，会怎么样
* Pod 会对重启一个docker
* delete Pod，资源消失(Pod没有控制器的情况下)
* Pod的控制器 RC RS  Deployment
    * rc
    * 对rc的升级
    * deployment 对rs的封装，是对应用的一次部署 发布，滚动更新。调用的是rs。滚动升级的时候，起一个新的rs，干掉一个旧的RS。。。
* service 对外提供服务
    * 公有云直接映射 ？？？
    * NodePort机制 流量先走宿主机的IP，通过iptables/ipvs跳转到service，然后走到Pod。
    


### RBAC 权限控制
API Server权限控制分为三种
Auth。。 身份认证
。。     授权
。。     准入
  
  
重点关注两种认证方式：token认证 证书认证

kubectl get serviceaccount -n kube-system
kubectl describe sa admin-user -n kube-system
kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | a wk '{print $1}')

kubectl config view

```bash
# 创建新的namespace mynginx 创建Pod
kubectl create ns mynginx
vim pod.yml
```
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: cent
  namespace: mynginx
  labels:
    run: cent
spec:
  containers:
  - name: cent
    image: nginx:1.13.12
    imagePullPolicy: IfNotPresent
```
```bash
kbc -f pod.yml
```
```bash
# 一、创建客户证书配置文件
cat > devuser-csr.json <<EOF
{
  "CN": "devuser",
  "hosts": [],
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "ST": "BeiJing",
      "L": "BeiJing",
      "O": "k8s",
      "OU": "System"
    }
  ]
}
EOF

# 二、在/etc/kubernetes/ssl目录生成客户端证书
cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes devuser-csr.json | cfssljson -bare devuser

# 三、验证证书
cfssl-certinfo -cert devuser.pem

# 四、执行命令
curl https://192.168.56.11:6443/api/v1/namespaces/kube-system/pods --cert /etc/kubernetes/ssl/devuser.pem --key /etc/kubernetes/ssl/devuser-key.pem --cacert /etc/kubernetes/ssl/ca.pem

# 五、创建角色
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: mynginx
  name: pod-reader
rules:
- apiGroups: [""] # "" indicates the core API group
  resources: ["pods"]
  verbs: ["get", "watch", "list"]

# 六、执行
kubectl create -f pod-reader.yml

# 七、创建绑定
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: read-pods
  namespace: mynginx
subjects:
- kind: User
  name: devuser   # 目标用户
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: Role
  name: pod-reader  # 角色信息
  apiGroup: rbac.authorization.k8s.io

# 八、执行绑定
kubectl create -f devuser-role-bind.yaml

# 九、验证角色权限
curl https://192.168.56.11:6443/api/v1/namespaces/kube-system/pods --cert /etc/kubernetes/ssl/devuser.pem --key /etc/kubernetes/ssl/devuser-key.pem --cacert /etc/kubernetes/ssl/ca.pem

curl -X DELETE  https://192.168.56.11:6443/api/v1/namespaces/mynginx/pods/cent  --cert /opt/kubernetes/ssl/devuser.pem --key /opt/kubernetes/ssl/devuser-key.pem --cacert /opt/kubernetes/ssl/ca.pem

# 编辑角色权限
kubectl edit role pod-reader -n mynginx

```

cluster-role 面向集群
role面向 具体的ns


#### .kube/config的管理
```bash
# kubectl config
```



#### dashboard 管理全局资源


![](https://tva1.sinaimg.cn/large/00831rSTly1gcqal2fx23j30ks0f376x.jpg)



## 高级应用篇

### 使用Helm管理Kubernetes应用


Helm 一个包管理工具
helm   ---> yum
chart  ---> rpm


```bash
 wget https://storage.googleapis.com/kubernetes-helm/helm-v2.9.1-linux-amd64.tar.gz
 tar zxf helm-v2.9.1-linux-amd64.tar.gz
 mv linux-amd64/helm /usr/local/bin/
 helm list
 helm init --upgrade  -i  registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.9.1 --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts
 kbg pod -n kube-system
 helm version
 kbg pod -n kube-system
 helm version
 kubectl get pod --all-namespaces|grep tiller
 kubectl create serviceaccount --namespace kube-system tiller
 kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller
 kubectl patch deploy --namespace kube-system tiller-deploy -p '{"spec":{"template":{"spec":{"serviceAccount":"tiller"}}}}'
 helm search jenkins
 helm repo list
 helm create helm-nginx
 cd helm-nginx/
 tree
 vim templates/deployment.yaml
 vim values.yaml
 vim values.yaml
 helm install --name helm-nginx .
 vim values.yaml
 helm install --name helm-nginx .
 helm list
 kbg pod
 helm -h
 helm  delete helm-nginx
 helm install --name helm-nginx .
 helm ls --all helm-nginx
 elm del --purge helm-nginx
 helm del --purge helm-nginx
 helm install --name helm-nginx .
 vim values.yaml
 helm del --purge helm-nginx
 helm install --name helm-nginx .
 vim values.yaml
 kbg pvc
```


## 资源配额 升级理解

### 基于Pod的资源限制

## stateFullSet 有状态服务
 - 分布式存储
 - 


## configmap

```bash
使用yaml文件创建；
使用kubectl configmap子命令创建；
从字面数值创建 
查看创建的configmaps
查看当前所有的configmaps
kubectl get configmaps
#以yaml的格式查看test-config这个configmap的内容
kubectl get configmap test-config -o yaml
#查看test-config这个configmap的详细信息
kubectl describe configmap test-config

kubectl logs
```

```bash
vim db.conf
#####
[test-abc]
url=www.igengmei.com
name=wangpenghong
age=18
#####

kubectl create configmap test-config2 --from-file=./db.conf
kubectl get cm 
```

```bash
vim damo.yaml
```
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: testcm3-pod  # pod name
spec:
  containers:
    - name: testcm3
      image: nginx:1.13.12 
      command: [ "/bin/sh", "-c", "cat /etc/config/abc.conf" ]
abc.conf" ]
      volumeMounts:
      - name: config-volume
        mountPath: /etc/config
  volumes:
    - name: config-volume
      configMap:
        name: demo2-test
```
```bash
kubectl create -f  damo.yaml
# 查看pod中打印的日志 能看到我们设置的db.conf的内容
kubectl logs logs testcm3-pod

# 在线更改mapconfig文件，不需要重启mapconfig
kubectl edit  cm test-config2
# 但是需要重启pod

# 注意：使用configmap 文件挂载的方式，挂在前后的文件名必须一致
```



## 架构

### 日志

### 监控
prometheus

### 备份

ETCD 
influxdb

### service mesh 

**istio**

### 日志采集



## 
说明:普通的 service 域名解析格式为:servicename.namespace.svc.cluster.local; 在 pod 之间调用可以适用 servicename.namespace; headless无头服务:就是把cluster ip设置为none的，会被解析为指定pod的 ip 列表;同样可以被解析为 podname.servicename.namespace.svc.cluster.local.
